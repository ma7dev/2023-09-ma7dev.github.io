[ { "title": "Weekly logs on Notion", "url": "/posts/weekly-logs/", "categories": "Productivity, Learning, Writing", "tags": "notion, obsidian", "date": "2022-12-24 00:00:00 -0800", "snippet": "For the last 6 years, I have been interested in writing and sharing my thoughts. I have written tens of drafts for articles that I think are useful, worth reading, and interesting to others, or at least to my young self. However, I haven’t published them because I feel that I haven’t provided enough evidence, my writing might sound naive, or even don’t feel qualified to write on those topics because I am not a (world) expert on them. This bothered me a lot that I have kept writing on my Obsidian vault (only a few have access to it) just to keep the momentum running.Therefore, I have decided that I will write something every Sunday and publish it about any topic that interests me. I will use Notion page to redirect to my Notion page for my weekly logs. The reason why I am using a separate page/subdomain for my weekly logs because I want to have my polished work to be on my main domain, ma7.dev, whereas, my half-baked but useful/interesting work on a separate domain, Notion page.Here is what you should expect that I will be talking about: Weekly overview of what I have consumed/learned throughout the week and include relevant resources. Progress updates for certain goals to keep me accountable while showing others what I am doing. Random thoughts about topics that I have been thinking of for some time.I hope that I will find this way to share what I know while still being useful to others and not stressful to me. Happy new year!" }, { "title": "How I write my notes [Part 1]", "url": "/posts/writing-notes/", "categories": "Productivity, Learning", "tags": "notion, obsidian, okular, mathpix, insync", "date": "2022-08-01 00:00:00 -0700", "snippet": "In this post, I will share the tools that I use, my general thoughts about the setup, and an example of how I would go about writing a note.Here are the tools that I use to have an active and productive experience when learning from books, courses, and general content (e.g. YT vids, online articles, etc.): Notion for project planning, reading list tracking, and scratch pad for logging and writing random notes for certain projects. It is basically used as a database and a tracker of the progression of my learning/consumption of the content. Obsidian for perma-notes and I use LYT setup, which is a fluid system to take notes. As I only read digital books, I use Okular as my pdf reader/highlighter. MathPix for converting equations to LaTeX equations to be imported to Obsidian. Insync to store my notes and pdf files on the cloud.My thoughts: As I have ADHD, it is easy to get distracted by multiple things and be focused on small and unimportant details, so my pipeline is structured (at least for me) while giving me the freedom to grow and mature as my learning experience is. My Obsidian notes are 1. an extension to my thoughts 2. organized of content. The notes aren’t meant to be read by others, they are meant for me to interact with the content. I believe in recycling information to develop a strong knowledge of some context. This means reading about backprop from school/traditional course will give me an idea of how backprop works, but when reading PyTorch’s implementation of backprop will give me more interesting and practical information about how backprop is actually implemented and used. Those two data point share backprop but they are learned at a different time of my life (which means I am a different person) so when creating the notes, they won’t be connected besides knowing their sources and they are related to Deep Learning note, which is enough connection. Hence, the parent note (Deep Learning note) is always organized to have a nice TOC of connected notes to ease the process of exploring my notes.Here is an example for when going through the Full Stack Deep Learning Course pre-labs: On Notion, I import the course structure and labs into my study_plan database and set pre-labs as Not started for me to view them into TODO tab. When I am ready to tackle any of the learning material, I use study_logs database as a scratch pad to write my thoughts while learning the material. Here is an example for the first lab. When I am done consuming the content, I move to Obsidian to write useful information to be stored to improve my knowledgebase system. Left note is for the lab 1 note and right note is for the course note where I use it as a TOC" }, { "title": "How I Learn", "url": "/posts/how-i-learn/", "categories": "Productivity, Learning", "tags": "learn, tools", "date": "2022-03-21 00:00:00 -0700", "snippet": "Requirements iPad Laptop/PC Google Drive/DropBox/any cloud storageConsume the contentWhen I read from an article, PDF, or any text-based resource, I follow the following rules: Use two highlighting colors (orange and green) and alternate between them to separate ideas. After reading for some time or feeling that I have lost or might lose track of what I have read before, I come back and write marginal notes (in red) to describe the general idea for each highlighted section. After completing reading the content, I revisit my notes and try to have a solid understanding of the content, and add more marginal notes with a different color (blue). Re-write my notes and general ideas into a piece of paper to understand the flow of ideas (just focus on important things and ignore details that aren’t important)Document ideasAfter I complete consuming the content, I move my notes to Obsidian to have them backed up in Markdown and organized for future reference. I try to refactor my notes every month or so.The connection between different markdown notes in Obsidian.Things that I useI use my iPad to write notes by hand and read PDFs. However, I have a different setup to organize my workflow: GoodNotes: to write notes from scratch. I use dark, square-style sheet I use three colors (yellow=main content, red and blue=side notes) Notability: to read and highlight on PDF. I use three highlighting colors (orange and green = highlighting ideas, and blue = for extremely important things or weird stuff that I want to look into later) I use two colors for marginal notes(red = during reading, and blue = after reading) Both of them are synced to Google Drive and I use insync to sync the documents created in both GoodNotes and Notability to my PC/Laptop.In addition, I use the following to do certain things: Mathpix: take a screenshot on pdf or hand-written equations to turn them into LaTeX equations (basically to be added to LaTeX or Markdown document) Google Drive: for cloud storage insync: to automatically backup my stuff between different machines Zotero: to manage pdf files Todoist: to manage tasks and reading content raindrop.io: to manage online content (smart bookmarks) Super Simple Highlighter: to highlight on the web" }, { "title": "[Project] Travelling salesman problem", "url": "/posts/tsp/", "categories": "Projects, Algorithms", "tags": "travelling-salesman-problem", "date": "2019-03-15 00:00:00 -0700", "snippet": "DescriptionThis is a final report for analysis of solving the travelling salesman problem using multiple algorithms and the analysis of those algorithms.Algorithms that Solve TSPBrute Force Search (Naive Algorithm)Run-time Analysis\\[O(n!)\\]Pseudo-code \\begin{algorithm}\\caption{Brute Force Search}\\begin{algorithmic}\\Procedure{BF}{$r$, $cititiesNotInRoute[1...n]$} \\If {$citiesNotInRoute.length != 0$} \\For{$i$ \\textbf{from} $0$ \\textbf{to} $citiesNotInRoute.length$} \\State $cityRemoved = popFront(cititiesNotInRoute)$ \\State $newRoute = r$ \\State $push(newRoute, cityRemoved)$ \\State $BF(newRoute, cititiesNotInRoute)$ \\State $push(cititiesNotInRoute, cityRemoved)$ \\EndFor \\EndIf \\If {$skip == true$} \\State $print(r)$ \\EndIf\\EndProcedure\\end{algorithmic}\\end{algorithm}DescriptionThis algorithm checks every vertices and every edges. Therefore, it is clear it will find the solution. The running time is $O(n!)$ because the starting vertex has $n-1$ edges to choose, next one has $n-2$ edges to choose, $… n-1$ vertex has $1$ edge to choose. Therefore, by multiply every edges, Icould get the running time which is $(n-1)!$. Since it is clear $(n-1)! &lt; n!$, I can say the running time is $O(n!)$.I choose this algorithm because it is the basic way to think about how to solve this problem. This algorithm is easy to make, but it is really slow. Therefore, this algorithm makes us to realize how important the algorithm is. Better algorithm makes way more faster program.Held-Karp Algorithm (Dynamic Algorithm)Run-time Analysis\\[O(n^{2} \\times 2^{n})\\]Pseudo-code \\begin{algorithm}\\caption{Held-Karp Algorithm}\\begin{algorithmic}\\Procedure{HK}{$G$, $n$} \\For{$k$ \\textbf{from} $2$ \\textbf{to} $n$} \\State $C(\\{k\\},k)=d_{1, k}$ \\EndFor \\For{$s$ \\textbf{from} $2$ \\textbf{to} $n-1$} \\For{$all\\ S \\subseteq \\{2,...,n\\}, |S|=s$} \\For{$all\\ k \\in S$} \\State $\\{C(S,k)=min_{m \\neq k, m \\in S}[C(S-\\{k\\},m)+d_{m, k}]\\}$ \\EndFor \\EndFor \\EndFor \\State $opt=min_{k \\neq 1}[C(\\{2, 3, ..., n\\}, k) + d_{k, 1}]$ \\State \\textbf{return} $opt$\\EndProcedure\\end{algorithmic}\\end{algorithm}DescriptionThis algorithm use dynamic algorithm to solve the problem. It first gets the distance between two vertices and save it to array. It is $O(n)$ steps. The next part is to find the minimum distance with small set of vertices. The for loop, for $s$ from $2$ to $n-1$ and for all $S$ in ${2, …, n}$, $|S| = s$, is defining small set of vertices. The next for loop is the part that getting the minimum distance from the set of vertices. Each set has s elements and it has to compare with s different minimum candidates, it has $O(s^{2})$ running time. The first two loop, which define the set S, has running time with $SUM_{i}=2^{n-1} (C(n-1,i))$ because there are $C(n-1, i)$ number of combination for defining set with $i$ elements, and since it is from $2$ to $n-1$, it makes $SUM_{i}=2^{n-1} (C(n-1,i)) \\times n^{2})$. Hence, it could be rewrite as $n^{2} \\times SUM_{i}=2^{n-1} (C(n-1,i))$ $&lt;= n^{2} \\times 2^{n-1} = \\frac{1}{2} \\times n^{2} \\times 2^{n}$ $= O(2^{n} \\times n^{2}$). I choose this algorithm because I learned dynamic programming and this algorithm use that concepts. This algorithm saves data into $C(S, n)$ and use it to find minimum distance. By this skill, this algorithm can find real answer with way more faster than the brute force method. However, it is still slow.K-Nearest Neighbor Algorithm (Approximation Algorithm)Run-time Analysis\\[O(n^{2})\\]Codedef Distance(a,b): return int(round(math.sqrt((math.pow(a['i'] - b['i'],2))+(math.pow(a['j'] - b['j'],2)))))def KNN(cities, inFile): matrix = [[-1 for x in range(len(cities))] for y in range(len(cities))] minLength = sys.maxsize order = [] for x in range(len(cities)): allCities = [z for z in cities] route = [] route.append(allCities[x]['city']) allCities.remove(allCities[x]) length = 0 while len(allCities) &gt; 0: current = cities[route[len(route)-1]] minDistance = sys.maxsize minCity = -1 for y in range(len(allCities)): currentDistance = matrix[current['city']][allCities[y]['city']] if currentDistance == -1: currentDistance = Distance(current, allCities[y]) matrix[current['city']][allCities[y]['city']] = currentDistance matrix[allCities[y]['city']][current['city']] = currentDistance if currentDistance &lt; minDistance: minDistance = currentDistance minCity = allCities[y] route.append(minCity['city']) allCities.remove(minCity) length += minDistance currentDistance = matrix[cities[route[0]]['city']][cities[route[len(route)-1]]['city']] if currentDistance == -1: currentDistance = Distance(cities[route[0]], cities[route[len(route)-1]]) matrix[cities[route[0]]['city']][cities[route[len(route)-1]]['city']] = currentDistance matrix[cities[route[len(route)-1]]['city']][cities[route[0]]['city']] = currentDistance length += currentDistance if length &lt; minLength: minLength = length order = [x for x in route] WriteFileKNN(inFile, order, minLength)DescriptionThis algorithm is greedy algorithm that finds the vertex with minimum weight and choose it. Therefore, the first vertex has to check $n-1$ edges and choose the minimum. Second one has to check n-2 edges and choose the minimum. The $n-1$ vertex choose $1$ edges. Hence, the running time is $SUM\\ 1\\ TO\\ N-1\\ = (N-1)(N-2)/2 = O(N^2)$. I choose this algorithm because I found that this is the fastest. This algorithm is greedy algorithm that choose only the nearest vertex from the start vertex, and keep finding the nearest vertex from the chosen one. Since it is just checking the nearest, there is possibility to find the wrong answer. However, I found that this algorithm finds reasonable path, which means not huge different than true answer, and the power of this algorithm is this is super fast. It is only $O(n^2)$. Therefore, this algorithm will be good choice when I need the result really quickly, andit is ok to have small error. I used a nearest neighbor algorithm written in Java to get inspiration for my Python program,found here: http://www.sanfoundry.com/java-program-implement-traveling-salesman-problem-using-nearest-neighbour-algorithm/. The program searches for the most optimal nearest neighbor route by using a brute-force wrapper for-loop to select each city as the starting point. The program is able to analyze eachcity for the smaller list sizes, but for the larger ones it cannot process each city within 5 minutes, so that is why I have a section of code in the main section of the program to end the algorithm after 5 minutes. Each time the algorithm finds a new shorter route it is written to the output file, so this ensures that I am still able to have a valid result at the very beginning, well before the 5 minute time constraint is over.Genetic Algorithm (Approximation Algorithm)Run-time Analysis\\[O(T \\times n_{0} \\times n^{2})\\]where $T$ is the number of outer iteration, $n_{0}$ is the initial size of the population, and $n$ is the number of cities.Codeclass City: def __init__(self, id, x, y): self.id = id self.x = x self.y = y def distance(self, city): # xDis = self.x - city.x # yDis = self.y - city.y # distance = np.sqrt((xDis ** 2) + (yDis ** 2)) return int(round(math.sqrt((math.pow(self.x - city.x,2))+(math.pow(self.y - city.y,2))))) def __repr__(self): return \"(\" + str(self.x) + \",\" + str(self.y) + \")\"class Fitness: def __init__(self, route): self.route = route self.distance = 0 self.fitness= 0.0 def routeDistance(self): if self.distance ==0: pathDistance = 0 for i in range(0, len(self.route)): fromCity = self.route[i] toCity = None if i + 1 &lt; len(self.route): toCity = self.route[i + 1] else: toCity = self.route[0] pathDistance += fromCity.distance(toCity) self.distance = pathDistance return self.distance def routeFitness(self): if self.fitness == 0: self.fitness = 1 / float(self.routeDistance()) return self.fitnessdef createRoute(cityList): route = random.sample(cityList, len(cityList)) return routedef initialPopulation(popSize, cityList): population = [] for i in range(0, popSize): population.append(createRoute(cityList)) return populationdef rankRoutes(population): fitnessResults = {} for i in range(0,len(population)): fitnessResults[i] = Fitness(population[i]).routeFitness() return sorted(fitnessResults.items(), key = operator.itemgetter(1), reverse = True)def selection(popRanked, eliteSize): selectionResults = [] df = pd.DataFrame(np.array(popRanked), columns=[\"Index\",\"Fitness\"]) df['cum_sum'] = df.Fitness.cumsum() df['cum_perc'] = 100*df.cum_sum/df.Fitness.sum() for i in range(0, eliteSize): selectionResults.append(popRanked[i][0]) for i in range(0, len(popRanked) - eliteSize): pick = 100*random.random() for i in range(0, len(popRanked)): if pick &lt;= df.iat[i,3]: selectionResults.append(popRanked[i][0]) break return selectionResultsdef matingPool(population, selectionResults): matingpool = [] for i in range(0, len(selectionResults)): index = selectionResults[i] matingpool.append(population[index]) return matingpooldef breed(parent1, parent2): child = [] childP1 = [] childP2 = [] geneA = int(random.random() * len(parent1)) geneB = int(random.random() * len(parent1)) startGene = min(geneA, geneB) endGene = max(geneA, geneB) for i in range(startGene, endGene): childP1.append(parent1[i]) childP2 = [item for item in parent2 if item not in childP1] child = childP1 + childP2 return childdef breedPopulation(matingpool, eliteSize): children = [] length = len(matingpool) - eliteSize pool = random.sample(matingpool, len(matingpool)) for i in range(0,eliteSize): children.append(matingpool[i]) for i in range(0, length): child = breed(pool[i], pool[len(matingpool)-i-1]) children.append(child) return childrendef mutate(individual, mutationRate): for swapped in range(len(individual)): if(random.random() &lt; mutationRate): swapWith = int(random.random() * len(individual)) city1 = individual[swapped] city2 = individual[swapWith] individual[swapped] = city2 individual[swapWith] = city1 return individualdef mutatePopulation(population, mutationRate): mutatedPop = [] for ind in range(0, len(population)): mutatedInd = mutate(population[ind], mutationRate) mutatedPop.append(mutatedInd) return mutatedPopdef nextGeneration(currentGen, eliteSize, mutationRate): popRanked = rankRoutes(currentGen) selectionResults = selection(popRanked, eliteSize) matingpool = matingPool(currentGen, selectionResults) children = breedPopulation(matingpool, eliteSize) nextGeneration = mutatePopulation(children, mutationRate) return nextGenerationdef GA(inFile, population, popSize, eliteSize, mutationRate, generations): pop = initialPopulation(popSize, population) # print(\"Initial distance: \" + str(1 / rankRoutes(pop)[0][1])) for i in range(0, generations): pop = nextGeneration(pop, eliteSize, mutationRate) # print(\"Final distance: \" + str(1 / rankRoutes(pop)[0][1])) bestRouteIndex = rankRoutes(pop)[0][0] bestRoute = pop[bestRouteIndex] WriteFileGA(inFile, bestRoute, 1 / rankRoutes(pop)[0][1])DescriptionThe genetic algorithm seems to solve different kind of problems pretty well, such as error detection, so I have thought to give it a try to solve the TSP. The implementation of the algorithm is extremely hard compared to KNN, so I need to refer to some online resource to build the algorithm on Python, the resource is found: https://towardsdatascience.com/evolution-of-a-salesman-a-complete-genetic-algorithm-tutorial-for-python-6fe5d2b3ca35. The algorithm starts with a population, a set of solutions, and every population another new population is generated to give better solutions, so as the depth of the population increases the algorithm should give better solutions in theory.TestingIn order to test that my program was actually producing valid results we used the supplied tsp-verifier.py program on each of my output routes. Each result was found to be valid.It seems that the K-Nearest Neighbor (KNN) algorithm give better results in matter of approximation of path took and speed compared to Genetic Algorithm (GA) in all cases when time is the limitation. However, as the complexity of the graph increases and there isn’t no time limits, the Genetic Algorithm can finish faster with higher approximation to the optimal path when the threshold to stop is set, compared to the KNN which takes almost 2 times longer on average to reach the same optimal path results.My best results when testing where Test 1, 2, 4, and 5 when using KNN, and GA failed in most cases besides Test 6 and 7, which gave the same results as KNN at the same time.Please view the next page to look into all of the results.   Optimal path length Predicted path length Ratio KNN 108159 130921 1.21 GA 108159 337541 3.12   Optimal path length Predicted path length Ratio KNN 2579 2975 1.15 GA 2579 27639 10.71   Optimal path length Predicted path length Ratio KNN 1573084 1936941 1.23 GA 1573084 1934200 1.22   Predicted path length Time took KNN 5911 0.014127969741821289 GA 10488 14.512681007385254}   Predicted path length Time took KNN 8011 0.11811113357543945 GA 32837 18.30189299583435   Predicted path length Time took KNN 14826 1.3867180347442627 GA 103387 34.44625997543335   Predicted path length Time took KNN 19711 12.897594213485718 GA 220727 73.32604813575745   Predicted path length Time took KNN 27128 123.83275985717773 GA 465770 200.42861986160278   Predicted path length Time took KNN 39834 299.0716700553894 GA 39834 299.00313663482666   Predicted path length Time took KNN 62110 299.6045079231262 GA 62110 299.00823521614075 " }, { "title": "Linux vs. FreeBSD vs. Windows", "url": "/posts/linux-vs-freebsd-vs-windows/", "categories": "OS, Analysis", "tags": "linux, freebsd, windows", "date": "2018-12-06 00:00:00 -0800", "snippet": "IntroductionThis paper presents a comparison between Linux, FreeBSD, and Windows in three areas: concurrency, I/O, and memory management. In addition, in each area, I will discussing about the differences and similarities between them.Concurrency ComparisonIn this section, I will be discussing about processes, threads, CPU scheduling, and other related information that I have found interesting for each operating system based on my research.LinuxEach process provides the resources needed to execute a program. A process has a virtual address space, executable code, open handles to system objects, a security context, a unique process identifier, environment variables, a priority class, minimum and maximum working set sizes, and at least one thread of execution. Each process is started with a single thread, often called the primary thread, but can create additional threads from any of its threads 1.To create a process in Linux, we will need to use Fork() system call, which creates a new process, called the child process, from the exiting process, called the parent process. The child process has its own process ID (PID). Fork() takes no argument and return process ID. Fork() returns negative value if the process isn’t created, zero if the child process is created, and positive value and a child process ID if Fork() returns from parent process. In addition, system call Fork() duplicate the same address space of the parent process and allocate to the child process. However, the child process doesn’t inherit timer and semaphore adjustment from the parent process 2.The following code sample demonstrates how to create a process in Linux 3:#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;errno.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdlib.h&gt;int main( ){ pid_t child_pid; child_pid = fork ( ); // Create a new child process; if (child_pid &gt;= 0) { if (child_pid == 0) { printf (\"child process successfully created!!\\n\"); printf (\"child PID = %d, parent PID = %d\\n\", getpid( ), getppid( ) ); exit(0); } } else { perror(\"fork\"); exit(0); }}Threads of execution, often shortened to threads, are the objects of activity within the process. Each thread includes a unique program counter, process stack, and set of processor registers. The kernel schedules individual threads, not processes. In traditional Unix systems, each process consists of one thread. In modern systems, however, multi-threaded programs consist of more than one thread are common 1.FreeBSDA process is a program in execution. Each process has an address space containing a mapping of its program’s object code and global variables, a set of kernel resources that it can name and on which it can operate using system calls, and at least one and possibly many threads that execute its code. Every process in the system is assigned a unique identifier termed the process identifier (PID). An PID is a common mechanism used by applications and by the kernel to reference processes and it is used by applications when the latter send a signal to a process and when receiving the exit status from a deceased process. There are two PIDs that are special important to to each process: the PID of the process itself and the PID of the process’s parent process. A process structure contains information that must always remain resident in main memory, along with references to other structures that remain resident 4.Every thread represents a virtual processor with a full context worth of register state and its own stack mapped into the address space. In addition, every thread running in the process has a corresponding kernel thread, with its own kernel stack that represents the user thread when it is executing in the kernel as a result of a system call, page fault, or signal delivery. The threads of a process operate in either user mode or kernel mode. In user mode, a thread executes application code with the machine in a non-privileged protection mode. Thread structure tracks information that needs to be resident only when the process is executing such as its kernel run-time stack. Both, process and thread, structures are allocated dynamically as part of process creation and are freed when the process is destroyed as it exits 4.The FreeBSD timeshare scheduler uses a priority-based scheduling policy that is biased to favor interactive programs, such as text editors, over long-running batch-type jobs. Interactive programs tend to exhibit short bursts of computation followed by periods of inactivity or I/O. The scheduling policy initially assigns a high execution priority to each thread and allows that thread to execute for a fixed time slice 4.WindowsA process is basically a program in execution. The execution of a process must progress in a sequential fashion. Each process is uniquely identified by a number called a process ID (PID). Similar to files, each process has one owner and group, and the owner and group permissions are used to determine which files and devices the process can open 5.In addition, to create a process in Windows, we will need to use CreateProcess function. CreateProcess function runs independently of the creating process, and the following code sample demonstrates how to create a process 5:#include &lt;windows.h&gt;#include &lt;stdio.h&gt;#include &lt;tchar.h&gt;void _tmain( int argc, TCHAR *argv[] ){ STARTUPINFO si; PROCESS_INFORMATION pi; ZeroMemory( &amp;si, sizeof(si) ); si.cb = sizeof(si); ZeroMemory( &amp;pi, sizeof(pi) ); if( argc != 2 ) { printf(\"Usage: %s [cmdline]\\n\", argv[0]); return; } // Start the child process. if( !CreateProcess( NULL, // No module name (use command line) argv[1], // Command line NULL, // Process handle not inheritable NULL, // Thread handle not inheritable FALSE, // Set handle inheritance to FALSE 0, // No creation flags NULL, // Use parent's environment block NULL, // Use parent's starting directory &amp;si, // Pointer to STARTUPINFO structure &amp;pi ) // Pointer to PROCESS_INFORMATION structure ) { printf( \"CreateProcess failed (%d).\\n\", GetLastError() ); return; } // Wait until child process exits. WaitForSingleObject( pi.hProcess, INFINITE ); // Close process and thread handles. CloseHandle( pi.hProcess ); CloseHandle( pi.hThread );}Windows implements a priority-driven, preemptive scheduling system, at least one of the highest priority ready threads always runs, with the caution that certain high-priority threads ready to run might be limited by the processors on which they might be allowed or preferred to run on, a phenomenon called processor affinity 6.General DiscussionFrom my research, they all have similar processes features and behaviors, and Windows’ threads are similar to FreeBSD in the current model and the interface definition for Windows’ threads are similar to Linux. In addition, FreeBSD and Windows have a similar CPU scheduling as they both use priority-queues. 12456.IO ComparisonIn this section, I will be discussing about I/O (block and character), data structures, algorithms, cryptography, I/O scheduling, types of devices, and other related information that I have found interesting for each operating system based on my research.FreeBSDThe basic model of the UNIX I/O system is a sequence of bytes that can be accessed either randomly or sequentially, and there aren’t any access methods and control blocks in typical UNIX user process. Different programs expect various levels of structure, but the kernel doesn’t impose structure on I/O. In addition, UNIX processes use a descriptor to reference I/O streams. Descriptors are small unsigned integers obtained from the open and socket system calls. Read and write system calls can be applied to descriptors to transfer data, and close system call can be used to dead-locate any descriptor. There are three types of descriptors, files, pipes, and sockets. Files are linear array bytes, has at least one name, exists until all its names are deleted explicitly, and no process holds a descriptor for it. Pipes are a linear array of bytes, no name, used as an I/O stream, it is unidirectional, and created by a pipe system call. Sockets are transient objects, used for interprocess communication, exists only as long as some process holds a descriptor referring to it, and created by a socket system call. Furthermore, hardware devices can be categorized as either block (structure) or character (unstructured). For block devices, they are typified by disks and magnetic tapes, the kernel supports read-modify-write-type buffering actions on block-oriented structured devices to allow latter to be read and written in a totally random byte addressed fashion, and the filesystems are created on block devices. For character devices, they are communication lines, raster plotters, and unbuffered magnetic tapes and disks, and are support large block I/O transfers 7.For previous editions of stream I/O system, the stream I/O system was based on the UNIX character I/O system, which allows a user process to open a way terminal port and then to insert appropriated kernel-processing modules and the modules that are being processed by the network protocols can be inserted in the appreciated kernel-processing modules. In addition, stacking a terminal-processing module on top of a network-processing module allowed flexible and efficient implementation of the network viral terminals within the kernel. In newer editions of stream I/O system ,such as 18th edition which was adopted in System V. However, the design of the networking facilities for 4.2BSD changed its approach based on the socket interface and flexible multi-player network architecture, which allows a single system to support multiple sets of networking protocols with stream, datagram, and other types of access. In addition, the user application and the kernel operate independently of each other for security. In 4.4BSD, the kernel doesn’t store I/O control blocks or other operating-system-related data structures in the application address space. Each user-level application is provided with an independent address space in which it executes its applications/processes. Moreover, the kernel makes most of the state changes invisible to the processes involved 7.FreeBSD supports two different disk encryption methods, GBDE and GELI, and both of the methods support different cryptographic algorithms that counter different threats. For GBDE, it is high-security (protecting the user as protecting the data), cryptographic key provided by the user, and when the key is lost, the data can’t be accessed. On the other hand, GELI protects the data but doesn’t protect the user, it uses FreeBSD’s cryptographic device driver, and takes advantage of its transparently 8.WindowsThe design goals for the Windows I/O system are to provide an abstraction of devices, both hardware and software to application with a selected features of the operating system, such as uniform security, high-performance asynchronous, high-level language support, etc. Windows I/O system is responsible for the connection between user model functionality, storage, and drivers with WDM WMI Routines, PnP Manager, Power Manager, and I/O Manager. For I/O Manager, it is the core of the Windows I/O system because it defines the order of the framework within which I/O requests are delivered to device drivers. Most I/O requests are represented as I/O Request Packet (IRP), which travels from one I/O system component to another. The design of Windows I/O system allows an individual application thread to manage multiple I/O requests concurrently 9.Moreover, I have found 4 interesting algorithms built within the driver structure, Initialization Routine, Opening Devices, IRP, and Completing an I/O Request. For the Initialization Routine, the I/O manager executes a driver’s Initialization Routine when it loads the driver into the operating system. Then, the Initialization Routine fills in the system data structures to register the rest of the driver’s routines with the I/O manager and performs any global driver initialization that is necessary. For the Opening Devices, a file object is in a kernel model data structure that represents a handle to a device, and this process allows synchronization and easy manipulation of the object files. For IRP, the IRP is where the I/O system stores information it needs to process an I/O request, so when a thread calls an I/O API, the I/O manager constructs an IRP to represent the operation as it progresses through the I/O system. For Completing an I/O Request, it starts when a driver calls IoCompleteRequest to inform the I/O manager that has completed process teh request specified in the IRP 9.I have found a good example10 of how to use IoCompleteRequest in a Windows machine to implement Completing an I/O Request.NTSTATUS CompleteRequest(PIRP Irp, NTSTATUS status, ULONG_PTR Information){ Irp-&gt;IoStatus.Status = status; Irp-&gt;IoStatus.Information = Information; IoCompleteRequest(Irp, IO_NO_INCREMENT); return status;}General DiscussionA comparison between FreeBSD, Linux, and Windows 2000, that FreeBSD and Linux have higher security compared to Windows 2000 because they are both open source and Windows 2000 is closed, which means the main developers need to detect errors in the system by themselve. However, FreeBSD has higher security than Linux beucase FreeBSD requires third parties verification of the system compared to Linux, which can accepts updates from anyone with minor verification. In addition, Windows 2000 is supported by most of device manufactures because its layered architecture and generic use of objects 1112.To sum up, it seems that FreeBSD has a Linux-like I/O system strcture compared to Windows which treats every file as an object. In addition, FreeBSD has higher security than Linux and Windows because FreeBSD has different methods to protect data. However, Windows is supported by most of device manufactures because its layered architecture and generic use of objects 7891112.Memory Management ComparisonIn this section, I will be discussing about memory management in FreeBSD and Windows based on my research.FreeBSDBerkeley Software Distribution (BSD) kernel handles process scheduling, memory management, symmetric multi-processing, device drivers, etc. In addition, for memory management in general, each process has its own private address and each address space is divided into 3 logical segments: text, data, and stack. For the text segment, it is read-only, has initialized and uninitialized data portions of a program, and, in most machines, a process can change the size of its text segment only when the segment’s contents are overlaid with data from the files system or when debugging in action. For the stack, it has application’s run-time stack and makes a system call in most machines. Lastly, initial contents of the segments of a child process are duplicated from the segments of a parent process. Moreover, for memory management inside the kernel, kernel often does allocation of memory that are needed for only the duration of a single system call, but in a user process, such as short-term memory, would be allocated on the run-time stack. Kernel’s memory isn’t feasible to allocate even moderate-sized blocks of memory on it because the kernel has a limited run-time stack 7.For memory management, kernel can’t easily deal with memory allocation errors and often can’t scheme. Therefore, getting the memory in the kernel is more complicated than in user-space. Moreover, kernel treats phsical pages as the basic unit of memory management and kernel represents every phsical page on the system with a struct page structure, which is defined in &lt;linux/mm_types.h&gt; 1.struct page { unsigned long flags; atomic_t _count; atomic_t _mapcount; unsigned long private; struct address_space *mapping; pgoff_t index; struct list_head lru; void *virtual;};The kernel can’t treat all pages as the same because the hardware limitation. Therefore, some pages can’t be used for certain because of their physical address in memory. Hence, kernel uses the zones to group pages of similar properties. Linux partitions the system’s pages into zones to have a pooling in place to satisfy allocations as needed. Although some allocations may require pages from a partiular zone, other allocations my pull from multiple zones. Each zone is represented by a struct zone, which is defined in &lt;linux/mmzone.h&gt; 1.struct zone { unsigned long watermark[NR_WMARK]; unsigned long lowmem_reserve[MAX_NR_ZONES]; struct per_cpu_pageset pageset[NR_CPUS]; spinlock_t lock; struct free_area free_area[MAX_ORDER] spinlock_t lru_lock; struct zone_lru { struct list_head list; unsigned long nr_saved_scan; } lru[NR_LRU_LISTS]; struct zone_reclaim_stat reclaim_stat; unsigned long pages_scanned; unsigned long flags; atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS]; int prev_priority; unsigned int inactive_ratio; wait_queue_head_t *wait_table; unsigned long wait_table_hash_nr_entries; unsigned long wait_table_bits; struct pglist_data *zone_pgdat; unsigned long zone_start_pfn; unsigned long spanned_pages; unsigned long present_pages; const char *name;};Kmalloc() is similar to malloc() in user-space, but it is just a simple interface for obtaining kernel memory in byte-sized chunks and it can be used to allocate pages. For freeing pages, we can use kfree(), which is definded in &lt;linux/slab.h&gt;, kfree() frees a block of memory previously allocated with kmalloc() 1. buf = kmalloc(BUF_SIZE, GFP_ATOMIC); if (!buf) /* error allocating memory ! */ ... kfree(buf);Free lists data structures are the default data structures in kernel. Due to the fact that allocating and freeing data structures is one of the most common operations inside any kernel has issues, slab layer is used to solve these issues. Slab layer acts as generic data structure-chaining layer and slab layer attempts to cache frequently used data structures as they tend to be allocated and freed often, prevent memory fragmentation, which is resulted from frequent allocation and deallocation, by cached free lists are arranged contiguously, and it has many other promises that slab layer attempts to provide 1.WindowsThe memory manager in Windows implements virtual memory, provides a core set of services such as memory mapped files, copy-on-write memory, large memory support, and underlying support for the cache manager.The memory manager creates the two memory pools, non-paged pool and paged pool, that the system uses to allocate memory. Non-paged pool and paged pool are located in the region of the address space that is reserved for the system and mapped into the virtual address space of each process. For the non-paged pool, it consists of virtual memory addresses that are guaranteed to reside in physical memory as long as the corresponding kernel objects are allocated. For the paged pool, it consists of virtual memory that can be paged in and out of the system. To improve performance, systems with a single processor have three paged pools, and multiprocessor systems have five paged pools 5.It seems that Windows uses VirtualAlloc() to use a page granularity, so using VirtualAlloc can result in higher memory usage and it allows you to specify additional options for memory allocation. In order to free pages, you need to use VirtualFree() 5.LPVOID WINAPI VirtualAlloc( _In_opt_ LPVOID lpAddress, _In_ SIZE_T dwSize, _In_ DWORD flAllocationType, _In_ DWORD flProtect);BOOL WINAPI VirtualFree( _In_ LPVOID lpAddress, _In_ SIZE_T dwSize, _In_ DWORD dwFreeType);General DiscussionWindows and Linux has different memory management structures. In Windows, memory management uses tree data structures, uses cluster demand paging, brings 8 pages in memory simultaneously, and page replacements uses First In First Out (FIFO) algorithm. In the other hand, in Linux, memory management uses linked lists data stricture, uses demand paging with no pre-paging and it doesn’t swap the entire process instead it uses a lazy swapper, swaps the necessary pages into memory only to avoid reading pages that won’t be used, which decreases swap time and amount of physical memory required, and page replacement uses Least Recently Used (LRU) algorithm 13.From my research, it seems that Windows is built for commercial use due it’s complex systems to handle large amount of data compared to linux and FreeBSD, and FreeBSD seems to follow most of Linux memory management style, but it is more stable than Linux by using different methods 15713.ConclusionTo conclude, I have discussed about the differences and similarity between Linux, FreeBSD, and Windows in these areas: concurrency, I/O, and memory management. Therefore, based on my research and understanding, I conclude that FreeBSD and Linux are an excellent operating systems because of their system simplicity compared to Windows. However, Windows complexity was made for a certain purpose, which is commercial use. In addition, FreeBSD seems to be more stable and secure than Linux. Other than that, all of the systems have similar general architecture and data flow, but they vary in the way they implement and process these parts.References R. Love,Linux Kernel Development, 3rd ed. Addison-Wesley Professional, 2010. &#8617; &#8617;2 &#8617;3 &#8617;4 &#8617;5 &#8617;6 &#8617;7 &#8617;8 Operating system-processes,”Available at https://www.tutorialspoint.com/operatingsystem/osprocesses.htm(2018/10/19). &#8617; &#8617;2 A. Vara, “How to create process in linux (part 10/15),” Available at https://www.engineersgarage.com/tutorials/introduction-linux-part-1015. &#8617; M. K. McKusick, G. Neville-Neil, and R. N. Watson,The Design and Implementation of the FreeBSD Operating System, 2nd ed. Addison-Wesley Professional, 2014. &#8617; &#8617;2 &#8617;3 &#8617;4 Memory management,” Available at https://docs.microsoft.com/en-us/windows/desktop/memory/memory-management(2018/05/30). &#8617; &#8617;2 &#8617;3 &#8617;4 &#8617;5 &#8617;6 M. E. Russinovich, D. A. Solomon, and A. Ionescu,Windows Internals, Part 1: Covering Windows Server 2008 R2 and Windows 7,6th ed. Redmond, WA, USA: Microsoft Press, 2012. &#8617; &#8617;2 M. K. McKusick, K. Bostic, M. J. Karels, and J. S. Quarterman,The Design and Implementation of the 4.4BSD Operating System.Redwood City, CA, USA: Addison Wesley Longman Publishing Co., Inc., 1996. &#8617; &#8617;2 &#8617;3 &#8617;4 &#8617;5 M. W. Lucas,Absolute Freebsd, 2Nd Edition, 2nd ed. San Francisco, CA, USA: No Starch Press, 2007. &#8617; &#8617;2 M. E. Russinovich, D. A. Solomon, and A. Ionescu,Windows Internals, Part 2: Covering Windows Server 2008 R2 and Windows 7(Windows Internals). Redmond, WA, USA: Microsoft Press, 2012. &#8617; &#8617;2 &#8617;3 H. Haftmann, “Completing i/o requests,” Available at https://www-user.tu-chemnitz.de/∼heha/oneywdm/ch05d.htm. &#8617; B. Bruce and M. Stokely, “Freebsd vs. linux vs. windows 2000,” Available at https://people.freebsd.org/∼murray/bsdflier.html. &#8617; &#8617;2 S. Hand, “Operating systems,” Available at https://www.cl.cam.ac.uk/teaching/1011/OpSystems/os1a-slides.pdf &#8617; &#8617;2 U. Essays, “Compare the memory management of windows with linux,” Available at https://www.ukessays.com/essays/engineering/compare-the-memory-management.php (2016/12/05). &#8617; &#8617;2 " }, { "title": "[Project] Exploring Robot", "url": "/posts/exploring-robot/", "categories": "Projects, Robots", "tags": "robots, project", "date": "2018-12-06 00:00:00 -0800", "snippet": "Instructions Code A* Download world.csvPreview the document Write a program to create a 4-connected graph and run an A* search from vertex (0,0) to vertex (19,19) across the obstacle map provided in world.csv. The world is a 20×20 grid of cells The world.csv file is an occupancy grid map: 1 means the grid cell is occupied and you can’t move through it Edge costs are 1 Your code should output the final path (either plot it or print out the vertex coordinates) and associated path cost. Comment your code to demonstrate that you understand the algorithm. What to turn in: A zip file of your commented A* code including world.csv. A cover sheet (PDF) listing: Web sites you used People you worked with The final path Your heuristic function (in English) How you implemented the graph and priority queue Any known bugs/issues A few notes: 4-connected means that you can travel from a cell to any of the cardinal neighbors (north, south, east, west). Broadly speaking, there are two ways you can represent the graph As an adjacency matrix with a function that returns valid neighbors for a given vertex when queried, or As a list of vertices and a list of edges. You need to demonstrate that you understand how the algorithm works and the best way to do this is to comment relevant lines of code. Marks will be awarded accordingly. There are plenty of resources are available to you online, you may take inspiration from existing implementations that you find, but see Note 3 above.Rubric and Grade Criteria Ratings   Pts Sends waypoints to the robot 3.0 pts Full Marks 0.0 pts No Marks 3.0 Uses SLAM to create a map 3.0 pts Full Marks 0.0 pts No Marks 3.0 Has a documented exploration strategy 7.0 pts Full Marks 0.0 pts No Marks 7.0 Strategy works in all world files (entire space visited) 7.0 pts Full Marks 0.0 pts No Marks 7.0 Mechanism for detecting unexplored area 5.0 pts Full Marks 0.0 pts No Marks 5.0 Mechanism for detecting when exploration strategy fails Failure case: didn’t get to way point, what do you do next? 7.0 pts Full Marks 0.0 pts No Marks 7.0 Algorithm/strategy for getting to unexplored area 3.0 pts Full Marks 0.0 pts No Marks 3.0 Behaves “reasonably” on other test worlds Doesn’t crash, makes some attempt to navigate to unexplored areas 5.0 pts Full Marks 0.0 pts No Marks 5.0 Total Points:     40.0 ReportDiscussion of the exploration problemIn this problem we are designing an exploration package utilizing the gmapping and nav_bundle packages to allow a simulated robot to explore an unknown environment. Our algorithm will have to set waypoints to move our robot towards the unexplored areas while avoiding obstacles. The robot should be reasonably robust to noisy odometry and mapping data, and it should be able to recognize when waypoints cannot be reached.Discussion of your gmapping and nav_bundle package implementationsFrom the gmapping bundle we are only using the occupancy grid. This grid is used to find “frontier” points (points between explored and unexplored areas). We are also reading the map meta data which gives us the resolution of the occupancy grid in meters/pixel. This gives us the ability to transform the occupancy grid data into Cartesian coordinates. The map is also saved when a waypoint is generated and used to verify that the robot is staying in known areas only, ensuring that the robot doesn’t run into walls even if it didn’t know about them before it calculated it’s path.From the nav_bundle package, we are using the waypoint commands: twist, base_link_goal, path_reset, move_base_cancel, and ready_pub. Clear and cancel are used to have the robot only pursue a single waypoint at a time. Waypoints generated using the occupancy grid which are then translated and rotated into the robot’s local coordinate system then set as a waypoint using Twist.Discussion of your waypoint allocation algorithmWaypoints are generated procedurally using an 61x61 filter that scans the frontier points on the occupancy grid. The robot’s exploration policy defines frontier points as being known unoccupied locations where the robot would end near unknown locations. This filter only selects points that are centered on an explored point, have no obstacles within a specified distance from the center, have a threshold percentage of unexplored cells, and aren’t where the robot has been before. These cells are then weighted by the percentage of unknown cells and euclidean distance from the robot. It then uses an A* algorithm to determine if there is a known path from the current location to the candidate location. Validating the path allows the robot to exclude candidate points that would be outside of the map or within obstacles.If the robot enters a region that was unexplored when the waypoint was created, it will clear the waypoint queue, cancel the current waypoint, turn 360 degrees, back up 1.5m, and generate a new waypoint. With the current implementation of the nav_bundle, the robot can select paths that pass through unknown locations. If the robot then passes though the unknown location and discovers that there is a wall blocking the path, the robot will not reroute in order to find the proper path. Instead, the robot will simply crash into the wall. To prevent incorrect path planning through unknown locations, we save how the map looked when the nav_bundle chose that path, and tell the robot to stop and reroute if we reach a location that was previously unknown, making our robot’s path robust to new information. \\begin{algorithm}\\caption{FindNextWaypoint}\\begin{algorithmic}\\Procedure{FindNextWaypoint}{$map$, $window\\_size$, $stride\\_length$, $visited\\_locations$, $robot\\_loc$, $avoidance\\_radius$, $empty\\_radius$, $RESOLUTION$}\\State $potential\\_candidates \\gets \\text{[]}$\\For{\\textbf{every} $center\\_cell \\textbf{ in } map \\textbf{ that is greater than } stride\\_length$ \\textbf{apart from each other}} % if the center and the surrounding cells are not empty: % continue \\State $skip \\gets false$ \\For{\\textbf{every} $neighbor\\_cell$\\textbf{ in a }$avoidance\\_radius$\\textbf{ away from }$center\\_cell$} \\If {alreadyVisited($visited\\_location$, $neighbor\\_cell$)} \\State $skip \\gets true$ \\State \\textbf{break} \\EndIf \\EndFor \\If {$skip == true$} \\State \\textbf{continue} \\EndIf \\For{\\textbf{every} $neighbor\\_cell$\\textbf{ in a }$empty\\_radius$\\textbf{ away from }$center\\_cell$} \\If {getMapValue($visited\\_location$) $\\neq$ $0$} \\State $skip \\gets true$ \\State \\textbf{break} \\EndIf \\EndFor \\If {$skip == true$} \\State \\textbf{continue} \\EndIf \\State $cell\\_sum \\gets \\text{sum(all cells within } window\\_size/2 \\text{ from } center\\_cell \\text{)}$\t\\State $potential\\_candidates\\text{.append(}center\\_cell\\text{)}$\\EndFor\\State $candidate \\gets \\text{sorted(}potential\\_candidates\\text{)} $\\State $candidate \\gets potential\\_candidates\\text{.pop()} $\\While{$\\textbf{not } \\text{reachableByAStar(} robot\\_loc, candidate\\text{)}$} \\State $candidate \\gets potential\\_candidates\\text{.pop()} $ \\State $best\\_loc=candidate$\\EndWhile\\State $candidate \\gets \\text{convert\\_row\\_col\\_to\\_coord}best\\_loc, RESOLUTION, map\\text{)} $\\State \\textbf{return} $candidate$\\EndProcedure\\end{algorithmic}\\end{algorithm} Inputs: map: The current occupancy grid window_size: Width of the sliding window used to generate candidate points stride_length: Row much to shift the sliding window with each iteration visited_locations: Grid with same size as map representing the locations we have been to robot_loc: Currently location of the robot avoidance_radius: Radius around candidate waypoint that should not contain walls empty_radius: Radius around candidate waypoint that should be empty RESOLUTION: How many meters per cell Outputs: candidate: The best potential waypoint to go to next Analysis of your algorithm’s exploration performanceThe algorithm has managed full coverage in all provided maps. This algorithm is far from perfect, periodically getting stuck (although it is able to correct itself), and periodically choosing waypoints outside of the map. The algorithm can struggle to come up with waypoints in a reasonable amount of time (typically 20 seconds) due to the need to run A* after a potential candidate is selected.The algorithm tended to get the robot stuck in one area, ensuring that every cell in the immediate area. This behavior causes the exploration process to take a long time in the maze map if it selects a point on the other side of a wall potentially causing long travel times.Did it result in full coverage of the environment (provide a screenshot from rviz)? \tFigure 1: Random Dots Map, The Office Map, and The Maze MapThis algorithm resulted in full exploration of the robot’s environment with a reasonable success rate. The many dots map was the first map that the robot completed, it completed the map in around 20 minutes. Euclidean distance in this map is an accurate way to approximate path distance since the map isn’t divided into rooms, making it an ideal scenario for this algorithm. The office map saw completion times of around 22 minutes. This was largely due to the euclidean distance heuristic that had the robot fully explore each room before moving on. This algorithm struggled with the maze file since it had a habit of setting waypoint on the other side of a wall making it drive back and forth around the entire map, making little but steady progress.Provide suggestions on how your waypoint allocation algorithm could be improved.The algorithm should use an A* search in order to find the nearest waypoints instead of using euclidean distance. This should make the exploration time faster since it would travel through fully explored areas less often in order to reach new locations. Computationally expensive functions (such as A*) could be rewritten in C++ in order to cut down on computational cost. The robot’s policy for getting unstuck could also be improved. Currently we assume that the robot gets stuck, it is facing a wall and can therefor get unstuck by backing up enough. However, it is not always the case that the wall is in front of the robot, and backing up could end up moving the robot into a wall. Instead, a better policy would be to turn and move away from the closest wall whenever the robot is stuck.Setup Download the file (source code) Unzip the file into the \\catkin_ws\\src directory In \\catkin_ws, run this command to buildcatkin_makeRun Open a new terminal In \\catkin_ws, run this command to source the bash filesource devel/setup.bash Run this command to launch the ros packageroslaunch src/rob456_project/launch/rob456_project.launch Open a new terminal In \\catkin_ws, run this command to source the bash filesource devel/setup.bash Run this command to launch the ros packageroslaunch src/nav_bundle/launch/nav_bundle.launch When the world starts, in rviz, select ‘2D Nav Goal’ and point to a closer cell that has been exploredContributors Lucas Frey - lcsfrey Mazen Alotaibi - ma7dev Daniel Boreham" } ]
